{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises: Modify the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File ../Data/employees.json does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Student\\Documents\\GitHub\\Data-Processing-Tobias-Englund\\Exercises\\E002_Modify_dataset.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Student/Documents/GitHub/Data-Processing-Tobias-Englund/Exercises/E002_Modify_dataset.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Student/Documents/GitHub/Data-Processing-Tobias-Englund/Exercises/E002_Modify_dataset.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m employees \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_json(\u001b[39m\"\u001b[39;49m\u001b[39m../Data/employees.json\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Student\\.virtualenvs\\GitHub-FsW2I2pH\\Lib\\site-packages\\pandas\\io\\json\\_json.py:780\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39mif\u001b[39;00m convert_axes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m orient \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtable\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    778\u001b[0m     convert_axes \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 780\u001b[0m json_reader \u001b[39m=\u001b[39m JsonReader(\n\u001b[0;32m    781\u001b[0m     path_or_buf,\n\u001b[0;32m    782\u001b[0m     orient\u001b[39m=\u001b[39;49morient,\n\u001b[0;32m    783\u001b[0m     typ\u001b[39m=\u001b[39;49mtyp,\n\u001b[0;32m    784\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    785\u001b[0m     convert_axes\u001b[39m=\u001b[39;49mconvert_axes,\n\u001b[0;32m    786\u001b[0m     convert_dates\u001b[39m=\u001b[39;49mconvert_dates,\n\u001b[0;32m    787\u001b[0m     keep_default_dates\u001b[39m=\u001b[39;49mkeep_default_dates,\n\u001b[0;32m    788\u001b[0m     precise_float\u001b[39m=\u001b[39;49mprecise_float,\n\u001b[0;32m    789\u001b[0m     date_unit\u001b[39m=\u001b[39;49mdate_unit,\n\u001b[0;32m    790\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m    791\u001b[0m     lines\u001b[39m=\u001b[39;49mlines,\n\u001b[0;32m    792\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m    793\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m    794\u001b[0m     nrows\u001b[39m=\u001b[39;49mnrows,\n\u001b[0;32m    795\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    796\u001b[0m     encoding_errors\u001b[39m=\u001b[39;49mencoding_errors,\n\u001b[0;32m    797\u001b[0m     dtype_backend\u001b[39m=\u001b[39;49mdtype_backend,\n\u001b[0;32m    798\u001b[0m     engine\u001b[39m=\u001b[39;49mengine,\n\u001b[0;32m    799\u001b[0m )\n\u001b[0;32m    801\u001b[0m \u001b[39mif\u001b[39;00m chunksize:\n\u001b[0;32m    802\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\n",
      "File \u001b[1;32mc:\\Users\\Student\\.virtualenvs\\GitHub-FsW2I2pH\\Lib\\site-packages\\pandas\\io\\json\\_json.py:893\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[1;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    891\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m filepath_or_buffer\n\u001b[0;32m    892\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mujson\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 893\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data_from_filepath(filepath_or_buffer)\n\u001b[0;32m    894\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[1;32mc:\\Users\\Student\\.virtualenvs\\GitHub-FsW2I2pH\\Lib\\site-packages\\pandas\\io\\json\\_json.py:949\u001b[0m, in \u001b[0;36mJsonReader._get_data_from_filepath\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    941\u001b[0m     filepath_or_buffer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n\u001b[0;32m    942\u001b[0m \u001b[39melif\u001b[39;00m (\n\u001b[0;32m    943\u001b[0m     \u001b[39misinstance\u001b[39m(filepath_or_buffer, \u001b[39mstr\u001b[39m)\n\u001b[0;32m    944\u001b[0m     \u001b[39mand\u001b[39;00m filepath_or_buffer\u001b[39m.\u001b[39mlower()\u001b[39m.\u001b[39mendswith(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    947\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[0;32m    948\u001b[0m ):\n\u001b[1;32m--> 949\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFile \u001b[39m\u001b[39m{\u001b[39;00mfilepath_or_buffer\u001b[39m}\u001b[39;00m\u001b[39m does not exist\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    950\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    951\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    952\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPassing literal json to \u001b[39m\u001b[39m'\u001b[39m\u001b[39mread_json\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    953\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwill be removed in a future version. To read from a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    957\u001b[0m     )\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File ../Data/employees.json does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "employees = pd.read_json(\"../Data/employees.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Current state of the \"employees\" dataset**\n",
    "\n",
    "Rerun the code block below after each modification you do, to see its current state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do the following operations on the \"employees\" dataset:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OP1:** Create a new column \"name\" which contains the full name (eg. \"John Doe\") for each employee.\n",
    "\n",
    "<details>\n",
    "<summary>Result</summary>\n",
    "<br>\n",
    "&nbsp;&nbsp;&nbsp;<b>name</b><br>\n",
    "&nbsp;&nbsp;&nbsp;John Doe<br>\n",
    "&nbsp;&nbsp;&nbsp;Jane Smith<br>\n",
    "&nbsp;&nbsp;&nbsp;Michael Johnson<br>\n",
    "&nbsp;&nbsp;&nbsp;...<br>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_full_name = employees['first_name'] + employees['last_name']\n",
    "print(employee_full_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: inline\">\n",
    "<b>OP2:</b> Create a new column \"email\" with the following format: firstname.lastname@mockcompany.com\n",
    "</div><br>\n",
    "\n",
    "*Note: email addresses should be all lower case.*\n",
    "\n",
    "<details>\n",
    "<summary>Result</summary>\n",
    "<br>\n",
    "&nbsp;&nbsp;&nbsp;<b>email</b><br>\n",
    "&nbsp;&nbsp;&nbsp;john.doe@mockcompany.com<br>\n",
    "&nbsp;&nbsp;&nbsp;jane.smith@mockcompany.com<br>\n",
    "&nbsp;&nbsp;&nbsp;michael.johnson@mockcompany.com<br>\n",
    "&nbsp;&nbsp;&nbsp;...<br>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OP3:** Remove the columns \"first_name\" and \"last_name\", and put the columns \"name\" and \"email\" first.\n",
    "<details>\n",
    "<summary>Result</summary>\n",
    "<br>\n",
    "&nbsp;&nbsp;&nbsp;<b>name&nbsp;&nbsp;&nbsp;email&nbsp;&nbsp;&nbsp;job_title&nbsp;&nbsp;&nbsp;salary&nbsp;&nbsp;&nbsp;department</b>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OP4:** Update column titles to make the first letter in each title upper case. Also replace the underscore character in \"job_title\" with a space.\n",
    "<details>\n",
    "<summary>Result</summary>\n",
    "<br>\n",
    "&nbsp;&nbsp;&nbsp;<b>Name&nbsp;&nbsp;&nbsp;Email&nbsp;&nbsp;&nbsp;Job title&nbsp;&nbsp;&nbsp;Salary&nbsp;&nbsp;&nbsp;Department</b>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OP5:** Change the data type of column \"Salary\" to float64.\n",
    "<details>\n",
    "<summary>Result</summary>\n",
    "<br>\n",
    "&nbsp;&nbsp;&nbsp;Salary: int64 => float64\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OP6:** The company decided to give everyone in sales a 10% salary increase. Update the dataset accordingly.\n",
    "\n",
    "<details>\n",
    "<summary>Result</summary>\n",
    "<br>\n",
    "&nbsp;&nbsp;&nbsp;John Doe&nbsp;&nbsp;&nbsp;132000.0<br>\n",
    "&nbsp;&nbsp;&nbsp;Jane Smith&nbsp;&nbsp;&nbsp;60000.0<br>\n",
    "&nbsp;&nbsp;&nbsp;Michael Johnson&nbsp;&nbsp;&nbsp;110000.0\t<br>\n",
    "&nbsp;&nbsp;&nbsp;Sarah Williams&nbsp;&nbsp;&nbsp;82500.0<br>\n",
    "&nbsp;&nbsp;&nbsp;...<br>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OP7:** The company hired a new software engineer. Add a new row with appropriate values to the dataset.\n",
    "<details>\n",
    "<summary>Result</summary>\n",
    "<br>\n",
    "<b>Example:</b><br>\n",
    "&nbsp;&nbsp;&nbsp;<b>Name:</b> Jennifer Lee<br>\n",
    "&nbsp;&nbsp;&nbsp;<b>Email:</b> jennifer.lee@mockcompany.com<br>\n",
    "&nbsp;&nbsp;&nbsp;<b>Job title:</b> Software Engineer<br>\n",
    "&nbsp;&nbsp;&nbsp;<b>Salary:</b> 100.000<br>\n",
    "&nbsp;&nbsp;&nbsp;<b>Department:</b> IT<br>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OP8:** The company decided to hire a lot of new software engineers.\n",
    "\n",
    "Create python code that asks the user to input the name and salary of the new software engineer, and then automatically adds the new employee to the dataset. Also, ensure that each employee get a unique index in the dataset.\n",
    "\n",
    "<details>\n",
    "<summary>Result</summary>\n",
    "<br>\n",
    "<b>Example:</b><br>\n",
    "&nbsp;&nbsp;&nbsp;Input name of new software engineer: Daniel Brown<br>\n",
    "&nbsp;&nbsp;&nbsp;Input the salary for Daniel Brown: 95.000<br>\n",
    "<br>\n",
    "&nbsp;&nbsp;&nbsp;<b>Name:</b> Daniel Brown<br>\n",
    "&nbsp;&nbsp;&nbsp;<b>Email:</b> daniel.brown@mockcompany.com<br>\n",
    "&nbsp;&nbsp;&nbsp;<b>Job title:</b> Software Engineer<br>\n",
    "&nbsp;&nbsp;&nbsp;<b>Salary:</b> 95.000<br>\n",
    "&nbsp;&nbsp;&nbsp;<b>Department:</b> IT<br>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OP9:** Olivia Moore quits her job. Remove her data from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OP10**: Make sure that the python script in *OP8* still gives a unique index to each new employee, even after removing rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final note:\n",
    "Just to be clear, a real company would most likely store their employee data in a database, and loading them into a pandas dataframe to do these kind of operations wouldn't make much sense. The above examples are purely for learning the different operations of pandas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Databehandling-AI23-toKGAHu0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
